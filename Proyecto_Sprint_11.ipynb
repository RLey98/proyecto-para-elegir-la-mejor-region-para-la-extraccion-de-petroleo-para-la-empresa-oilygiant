{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0d8a5c",
   "metadata": {},
   "source": [
    "# Proyecto para elegir la mejor región para la extracción de petróleo para la empresa OilyGiant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02747cdc",
   "metadata": {},
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducción](#intro)\n",
    "* [Etapa 1. Análisis exploratorio de datos](#data_review)\n",
    "    * [Inicialización](#initialization)\n",
    "    * [Cargar datos](#upload_data)\n",
    "* [Etapa 2. Segmentación de conjuntos de datos](#split_data)\n",
    "    * [Escalado de características](#feature_scaling)\n",
    "* [Etapa 3. Evaluación de modelo](#model_evaluation)\n",
    "* [Etapa 4. Preparación de calculo de ganancias](#profit_preparation)\n",
    "* [Etapa 5. Calcular las ganancias de un conjunto de pozos de petróleo seleccionados y modelar las predicciones](#profits_wells_calculation)\n",
    "* [Etapa 6. Calcular riesgos y ganancias para cada región](#risks_and_profits_calculation)\n",
    "* [Conclusión general](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae3870",
   "metadata": {},
   "source": [
    "# Introducción<a id='intro'></a>\n",
    "\n",
    "Tras tener los datos sobre muestras de crudo de tres regiones, los cuales se tiene que encontrar los mejores lugares donde abrir 200 pozos nuevos de petróleo. Se conocen los parámetros de cada pozo petrolero de la región. Se plantea crear un modelo que ayude a elegir la región con el mayor margen de beneficio. Y analizar los beneficios y riesgos potenciales utilizando la técnica bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23700395",
   "metadata": {},
   "source": [
    "# Etapa 1. Análisis exploratorio de datos<a id='data_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfb8e0",
   "metadata": {},
   "source": [
    "## Inicialización<a id='initialization'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790c9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcab43",
   "metadata": {},
   "source": [
    "## Cargar datos<a id='upload_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa3d874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "Datos Duplicados:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txEyH</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>-0.497823</td>\n",
       "      <td>1.221170</td>\n",
       "      <td>105.280062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2acmU</td>\n",
       "      <td>1.334711</td>\n",
       "      <td>-0.340164</td>\n",
       "      <td>4.365080</td>\n",
       "      <td>73.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409Wp</td>\n",
       "      <td>1.022732</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>1.419926</td>\n",
       "      <td>85.265647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iJLyR</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>0.139033</td>\n",
       "      <td>2.978566</td>\n",
       "      <td>168.620776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xdl7t</td>\n",
       "      <td>1.988431</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>4.751769</td>\n",
       "      <td>154.036647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>DLsed</td>\n",
       "      <td>0.971957</td>\n",
       "      <td>0.370953</td>\n",
       "      <td>6.075346</td>\n",
       "      <td>110.744026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>QKivN</td>\n",
       "      <td>1.392429</td>\n",
       "      <td>-0.382606</td>\n",
       "      <td>1.273912</td>\n",
       "      <td>122.346843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>3rnvd</td>\n",
       "      <td>1.029585</td>\n",
       "      <td>0.018787</td>\n",
       "      <td>-1.348308</td>\n",
       "      <td>64.375443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7kl59</td>\n",
       "      <td>0.998163</td>\n",
       "      <td>-0.528582</td>\n",
       "      <td>1.583869</td>\n",
       "      <td>74.040764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1CWhH</td>\n",
       "      <td>1.764754</td>\n",
       "      <td>-0.266417</td>\n",
       "      <td>5.722849</td>\n",
       "      <td>149.633246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        f0        f1        f2     product\n",
       "0      txEyH  0.705745 -0.497823  1.221170  105.280062\n",
       "1      2acmU  1.334711 -0.340164  4.365080   73.037750\n",
       "2      409Wp  1.022732  0.151990  1.419926   85.265647\n",
       "3      iJLyR -0.032172  0.139033  2.978566  168.620776\n",
       "4      Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
       "...      ...       ...       ...       ...         ...\n",
       "99995  DLsed  0.971957  0.370953  6.075346  110.744026\n",
       "99996  QKivN  1.392429 -0.382606  1.273912  122.346843\n",
       "99997  3rnvd  1.029585  0.018787 -1.348308   64.375443\n",
       "99998  7kl59  0.998163 -0.528582  1.583869   74.040764\n",
       "99999  1CWhH  1.764754 -0.266417  5.722849  149.633246\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./datasets/geo_data_0.csv\")\n",
    "df2 = pd.read_csv(\"./datasets/geo_data_1.csv\")\n",
    "df3 = pd.read_csv(\"./datasets/geo_data_2.csv\")\n",
    "\n",
    "df1.info()\n",
    "print(\"\\nDatos Duplicados: \", df1.duplicated().sum())\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29209ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "Datos Duplicados:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kBEdx</td>\n",
       "      <td>-15.001348</td>\n",
       "      <td>-8.276000</td>\n",
       "      <td>-0.005876</td>\n",
       "      <td>3.179103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62mP7</td>\n",
       "      <td>14.272088</td>\n",
       "      <td>-3.475083</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>26.953261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vyE1P</td>\n",
       "      <td>6.263187</td>\n",
       "      <td>-5.948386</td>\n",
       "      <td>5.001160</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KcrkZ</td>\n",
       "      <td>-13.081196</td>\n",
       "      <td>-11.506057</td>\n",
       "      <td>4.999415</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHL4O</td>\n",
       "      <td>12.702195</td>\n",
       "      <td>-8.147433</td>\n",
       "      <td>5.004363</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>QywKC</td>\n",
       "      <td>9.535637</td>\n",
       "      <td>-6.878139</td>\n",
       "      <td>1.998296</td>\n",
       "      <td>53.906522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>ptvty</td>\n",
       "      <td>-10.160631</td>\n",
       "      <td>-12.558096</td>\n",
       "      <td>5.005581</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>09gWa</td>\n",
       "      <td>-7.378891</td>\n",
       "      <td>-3.084104</td>\n",
       "      <td>4.998651</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>rqwUm</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>-6.152593</td>\n",
       "      <td>1.000146</td>\n",
       "      <td>30.132364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>relB0</td>\n",
       "      <td>-3.426139</td>\n",
       "      <td>-7.794274</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>3.179103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         f0         f1        f2     product\n",
       "0      kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
       "1      62mP7  14.272088  -3.475083  0.999183   26.953261\n",
       "2      vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
       "3      KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
       "4      AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
       "...      ...        ...        ...       ...         ...\n",
       "99995  QywKC   9.535637  -6.878139  1.998296   53.906522\n",
       "99996  ptvty -10.160631 -12.558096  5.005581  137.945408\n",
       "99997  09gWa  -7.378891  -3.084104  4.998651  137.945408\n",
       "99998  rqwUm   0.665714  -6.152593  1.000146   30.132364\n",
       "99999  relB0  -3.426139  -7.794274 -0.003299    3.179103\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.info()\n",
    "print(\"\\nDatos Duplicados: \", df2.duplicated().sum())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fca8a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "Datos Duplicados:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwXo0</td>\n",
       "      <td>-1.146987</td>\n",
       "      <td>0.963328</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>27.758673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WJtFt</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.269839</td>\n",
       "      <td>-2.530187</td>\n",
       "      <td>56.069697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ovLUW</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-5.586433</td>\n",
       "      <td>62.871910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q6cA6</td>\n",
       "      <td>2.236060</td>\n",
       "      <td>-0.553760</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>114.572842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WPMUX</td>\n",
       "      <td>-0.515993</td>\n",
       "      <td>1.716266</td>\n",
       "      <td>5.899011</td>\n",
       "      <td>149.600746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>4GxBu</td>\n",
       "      <td>-1.777037</td>\n",
       "      <td>1.125220</td>\n",
       "      <td>6.263374</td>\n",
       "      <td>172.327046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>YKFjq</td>\n",
       "      <td>-1.261523</td>\n",
       "      <td>-0.894828</td>\n",
       "      <td>2.524545</td>\n",
       "      <td>138.748846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>tKPY3</td>\n",
       "      <td>-1.199934</td>\n",
       "      <td>-2.957637</td>\n",
       "      <td>5.219411</td>\n",
       "      <td>157.080080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>nmxp2</td>\n",
       "      <td>-2.419896</td>\n",
       "      <td>2.417221</td>\n",
       "      <td>-5.548444</td>\n",
       "      <td>51.795253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>V9kWn</td>\n",
       "      <td>-2.551421</td>\n",
       "      <td>-2.025625</td>\n",
       "      <td>6.090891</td>\n",
       "      <td>102.775767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        f0        f1        f2     product\n",
       "0      fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
       "1      WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
       "2      ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
       "3      q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
       "4      WPMUX -0.515993  1.716266  5.899011  149.600746\n",
       "...      ...       ...       ...       ...         ...\n",
       "99995  4GxBu -1.777037  1.125220  6.263374  172.327046\n",
       "99996  YKFjq -1.261523 -0.894828  2.524545  138.748846\n",
       "99997  tKPY3 -1.199934 -2.957637  5.219411  157.080080\n",
       "99998  nmxp2 -2.419896  2.417221 -5.548444   51.795253\n",
       "99999  V9kWn -2.551421 -2.025625  6.090891  102.775767\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.info()\n",
    "print(\"\\nDatos Duplicados: \", df3.duplicated().sum())\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e16d23",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Al estudiar los datos de los tres dfs podemos ver que se trata de una region por df donde los tres poseen el mismo numero de 5 columnas (id del cliente, f0, f1, f2 y producto(volumen de reservas en el pozo de petróleo)). \n",
    "\n",
    "Teniendo 100,000 filas en cada uno de los df, no se presentan datos ausentes y los tipos de datos de cada columna de cada df están correctos. De igual forma también no presenta datos duplicados en ningun df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e5d7ab",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c645fd5",
   "metadata": {},
   "source": [
    "# Etapa 2. Segmentación de conjuntos de datos<a id='split_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca2fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una funcion donde definimos las caracteristicas y el objetivo\n",
    "def split_data(df):\n",
    "    \n",
    "    target = df['product']\n",
    "    features = df.drop([\"product\",\"id\"], axis=1)\n",
    "    \n",
    "    # Separamos los datos en conjuntos de entrenamiento y validación \n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "    return features_train, features_valid, target_train, target_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a4ab263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "#Llamamos a la funcion y almacenamos los conjuntos de datos en sus respectivas variables\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = split_data(df1)\n",
    "\n",
    "print(features_train_1.shape)\n",
    "print(features_valid_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "098349a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "#Llamamos a la funcion y almacenamos los conjuntos de datos en sus respectivas variables\n",
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = split_data(df2)\n",
    "\n",
    "print(features_train_2.shape)\n",
    "print(features_valid_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7688099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "#Llamamos a la funcion y almacenamos los conjuntos de datos en sus respectivas variables\n",
    "features_train_3, features_valid_3, target_train_3, target_valid_3 = split_data(df3)\n",
    "\n",
    "print(features_train_3.shape)\n",
    "print(features_valid_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc02b7",
   "metadata": {},
   "source": [
    "## Escalado de características<a id='feature_scaling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba863ab",
   "metadata": {},
   "source": [
    "Debido a que trabajaremos con un modelo de regresión lineal escalaremos los datos para este modelo debido a que existe una diferencia de escalas entre las columnas f0, f1 y f2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e02c2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una funcion para escalar las caracteristicas de los 3 dfs (3 regiones)\n",
    "def scale_data(features_train, features_valid):\n",
    "    #Creamos una lista de las columnas para el escalado\n",
    "    numeric_cols = ['f0', 'f1', 'f2']\n",
    "    #Creamos una instancia del StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    #Realizamos una copia de los datos de caracteristicas y los almacenamos como nuevas variables\n",
    "    features_train_scaled = features_train.copy()\n",
    "    features_valid_scaled = features_valid.copy()\n",
    "    \n",
    "    #Escalamos los datos con las caracteristicas de entrenamiento y transformamos los conjuntos de entrenamiento y validacion\n",
    "    scaler.fit(features_train_scaled[numeric_cols])\n",
    "    \n",
    "    features_train_scaled[numeric_cols] = scaler.transform(features_train_scaled[numeric_cols])\n",
    "    features_valid_scaled[numeric_cols] = scaler.transform(features_valid_scaled[numeric_cols])\n",
    "    \n",
    "    return features_train_scaled, features_valid_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74d9a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamamos a la funcion y almacenamos los conjuntos de datos escalados\n",
    "features_train_scaled_1, features_valid_scaled_1 = scale_data(features_train_1, features_valid_1)\n",
    "features_train_scaled_2, features_valid_scaled_2 = scale_data(features_train_2, features_valid_2)\n",
    "features_train_scaled_3, features_valid_scaled_3 = scale_data(features_train_3, features_valid_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565e6e9",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Podemos observar como mediante la function train_test_split es posible dividir los datos de los 3 dfs en primera instancia un 75% de entrenamiento y un 25% de validacion. De igual forma mediante StandardScaler escalamos los datos para el modelo de regresion lineal debido a que existe una diferencia de escalas entre las columnas f0, f1 y f2. Tambien mencionando como desarrollar todo esto dentro de una funcion es posible llamar a esta misma para que se aplique a los 3 dfs y se pueda reutilizar el codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c358fd6",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d7299",
   "metadata": {},
   "source": [
    "# Etapa 3. Evaluación de modelo<a id='model_evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38b085ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una funcion para entrenar el modelo y realizar predicciones\n",
    "def model_training_and_predictions(features_train, features_valid, target_train, target_valid):\n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    \n",
    "    #Obtenemos el error cuadratico medio, su raiz cuadrada, el volumen medio de las predicciones y el volumen medio del objetivo\n",
    "    mse = mean_squared_error(target_valid, predictions)\n",
    "    rmse = mse ** 0.5\n",
    "    predictions_volume_mean = predictions.mean()\n",
    "    target_volume_mean = target_valid.mean()\n",
    "    \n",
    "    print(\"ECM:\", mse)\n",
    "    print(\"RECM:\", rmse)\n",
    "    print(\"Volumen Medio de las Predicciones:\", predictions_volume_mean)\n",
    "    print(\"Volumen Medio del Objetivo:\", target_volume_mean)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2d4d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECM: 1412.2129364399243\n",
      "RECM: 37.5794217150813\n",
      "Volumen Medio de las Predicciones: 92.59256778438035\n",
      "Volumen Medio del Objetivo: 92.07859674082927\n"
     ]
    }
   ],
   "source": [
    "valid_predictions_1 = model_training_and_predictions(features_train_scaled_1, features_valid_scaled_1, target_train_1, target_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3493b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECM: 0.7976263360391157\n",
      "RECM: 0.893099286775617\n",
      "Volumen Medio de las Predicciones: 68.728546895446\n",
      "Volumen Medio del Objetivo: 68.72313602435997\n"
     ]
    }
   ],
   "source": [
    "valid_predictions_2 = model_training_and_predictions(features_train_scaled_2, features_valid_scaled_2, target_train_2, target_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "439a0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECM: 1602.377581323619\n",
      "RECM: 40.02970873393434\n",
      "Volumen Medio de las Predicciones: 94.96504596800489\n",
      "Volumen Medio del Objetivo: 94.88423280885438\n"
     ]
    }
   ],
   "source": [
    "valid_predictions_3 = model_training_and_predictions(features_train_scaled_3, features_valid_scaled_3, target_train_3, target_valid_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75dbafb",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Al entrenar el modelo, realizar las predicciones y calcular las metricas en las 3 regiones en donde obtenemos lo siguiente:\n",
    "\n",
    "* En la region 1, tenemos que el valor de error cuadratico medio es de 1412.21 y la raiz del error cuadratico medio es de 37.57, significando un error considerable el cual no se puede ignorar, aproximado de 37 mil barrilles. De igual forma vemos como el promedio del volumen de predicciones es de 92.5925 y el promedio del volumen objetivo es de 92.0785, siendo volumenes medios muy similares.\n",
    "\n",
    "* En la region 2, tenemos que el valor de error cuadratico medio es de 0.797 y la raiz del error cuadratico medio es de 0.893, significando un error muy bajo, aproximado de menos de un barril. De igual forma vemos como el promedio del volumen de predicciones es de 68.7285 y el promedio del volumen objetivo es de 68.7231, siendo volumenes medios igual muy similares.\n",
    "\n",
    "* En la region 3, tenemos que el valor de error cuadratico medio es de 1602.37 y la raiz del error cuadratico medio es de 40.02, significando un error considerable el cual no se puede ignorar, aproximado de 40 mil barrilles. De igual forma vemos como el promedio del volumen de predicciones es de 94.9650 y el promedio del volumen objetivo es de 94.8842, siendo volumenes medios muy similares.\n",
    "\n",
    "En este caso, podemos observar como en la region 2 tiene el menor error posible de las tres regiones, y siendo la region 3 con el mayor error de los 3. De igual forma vemos que la region 3 tiene el mayor volumen promedio y la region 2 teniendo el menor volumne promedio de los 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42622791",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70cd9d",
   "metadata": {},
   "source": [
    "# Etapa 4. Preparación de calculo de ganancias<a id='profit_preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e83cd",
   "metadata": {},
   "source": [
    "Almacenamos los valores necesarios para los calculos en sus respectivas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d579c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000.0\n",
      "111.11111111111111\n"
     ]
    }
   ],
   "source": [
    "investment = 100000000\n",
    "wells = 200\n",
    "sample = 500\n",
    "product_income_unit = 4500\n",
    "investment_per_well = investment / wells\n",
    "min_volume_unit = investment_per_well / product_income_unit\n",
    "print(investment_per_well)\n",
    "print(min_volume_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00de6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos en Series los conjuntos de datos de las predicciones y objetivos\n",
    "sample_target_1 = pd.Series(target_valid_1)\n",
    "sample_predictions_1 = pd.Series (valid_predictions_1, index = target_valid_1.index)\n",
    "sample_target_2 = pd.Series(target_valid_2)\n",
    "sample_predictions_2 = pd.Series (valid_predictions_2, index = target_valid_2.index)\n",
    "sample_target_3 = pd.Series(target_valid_3)\n",
    "sample_predictions_3 = pd.Series (valid_predictions_3, index = target_valid_3.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130bffe",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Como se puede observar para preparar el calculo de ganancias potenciales que se realizara en la siguiente etapa, declaramos todos los valores necesarios para el calculo, como por ejemplo la cantidad de pozos(wells), la inversion(investment), el ingreso por pozo(investment_per_well), etc. De igual forma convertimos todos los conjuntos de datos(objetivos y predicciones) a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909754f4",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73e7eb",
   "metadata": {},
   "source": [
    "# Etapa 5. Calcular las ganancias de un conjunto de pozos de petróleo seleccionados y modelar las predicciones<a id='profits_wells_calculation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ad17bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una funcion para seleccionar los 200 pozos de predicciones mas altos, los alamacenamos y calculamos la ganancia potencial\n",
    "def profit_calculation(target, predictions, wells, investment, product_income_unit):\n",
    "    #Ordenamos las predicciones de forma descendente\n",
    "    predictions_sorted = predictions.sort_values(ascending=False)\n",
    "    #Sellecionamos los 200 pozos\n",
    "    predictions_selected = target[predictions_sorted.index][:wells]\n",
    "    #Calculamos la ganancia potencial y retornamos el resultado\n",
    "    result = (product_income_unit * predictions_selected.sum()) - investment\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8797286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamamos a la funcion y almacenamos la ganacia potencial que es lo que retorna de la funcion\n",
    "profit_1 = profit_calculation(sample_target_1, sample_predictions_1, wells, investment, product_income_unit)\n",
    "profit_2 = profit_calculation(sample_target_2, sample_predictions_2, wells, investment, product_income_unit)\n",
    "profit_3 = profit_calculation(sample_target_3, sample_predictions_3, wells, investment, product_income_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e42cec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancias de los 200 mejores pozos petroleros de la region 1: 33208260.43139851\n",
      "Ganancias de los 200 mejores pozos petroleros de la region 2: 24150866.966815114\n",
      "Ganancias de los 200 mejores pozos petroleros de la region 3: 27103499.635998324\n"
     ]
    }
   ],
   "source": [
    "print(\"Ganancias de los 200 mejores pozos petroleros de la region 1:\", profit_1)\n",
    "print(\"Ganancias de los 200 mejores pozos petroleros de la region 2:\", profit_2)\n",
    "print(\"Ganancias de los 200 mejores pozos petroleros de la region 3:\", profit_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50f07f",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Como podemos observar mediante la funcion creada en conjunto del uso de las variables declaradas en la anterior etapa se obtuvieron las ganancias potenciales de los 200 mejores pozos de cada una de las 3 regiones, de las cuales la region 1 tiene la mayor ganancia con 33,208,260.43139, siguiendo la region 3 con una ganancia de 27,103,499.63599 y finalmente la region 2 que tiene la menor ganacia de las 3 con 24,150,866.96681.\n",
    "\n",
    "A simple vista con respecto las ganacias se podria proponer la region 1 como elegida para el desarrollo de pozos petrolíferos debido a que tiene la mayor ganacia de las 3 regiones. Sin embargo a pesar de esto seria muy apresurado el proponer la region 1 sin realizar alguna tecnica para evaluar la incertidumbre y los riesgos como el bootstrapping, sin olvidar que al realizar las predicciones para cada region se resalta que la region 1 ademas de tener la mayor ganancia tambien tuvo un RECM bastante considerable en sus predicciones a comparacion de ña region 2 que fue muy minimo el RECM. Por lo tanto antes de tomar una decision es preciso aplicar la tecnica de bootstrapping que se realizara en la siguiente etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d277152c",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f48be",
   "metadata": {},
   "source": [
    "# Etapa 6. Calcular riesgos y ganancias para cada región<a id='risks_and_profits_calculation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f4a2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una funcion para aplicar la tecnica del bootstrapping\n",
    "def bootstrapping(target, predictions, wells, investment, product_income_unit):\n",
    "    \n",
    "    #Creamos una instancia para que el estado de random_state sea aleatorio\n",
    "    state = np.random.RandomState(12345)\n",
    "    values = []\n",
    "    \n",
    "    for i in range(1000):\n",
    "        #Creamos submuestras de las predicciones y objetivo mediante bootstrapping y con esas submuestras llamamos a la funcion que calcula la ganancia potencial\n",
    "        target_subsample = target.sample(n=500, replace=True, random_state=state)\n",
    "        predictions_subsample = predictions[target_subsample.index]\n",
    "        profit = profit_calculation(target_subsample, predictions_subsample, wells, investment, product_income_unit)\n",
    "        #Almacenamos las ganancias\n",
    "        values.append(profit)\n",
    "\n",
    "    #Convertimos la lista de valores(ganancias) en un Series\n",
    "    values = pd.Series(values)\n",
    "    #Obtenemos el intervalo de confianza de 95% al obtener los cuantiles de 2.5% y 97.5%\n",
    "    lower = values.quantile(0.025)\n",
    "    upper = values.quantile(0.975)\n",
    "    #Obtenemos el beneficio promedio\n",
    "    mean = values.mean()\n",
    "    #Obtenemos el riesgo de perdidas\n",
    "    risk = (values < 0).mean()\n",
    "\n",
    "    print(f\"Intervalo de confianza del 95%: ({lower} , {upper})\")\n",
    "    print(\"Beneficio promedio:\", mean)\n",
    "    print(\"Cuantil del 97.5 %:\", upper)\n",
    "    print(\"Cuantil del 2.5 %:\", lower)\n",
    "    print(f\"Riesgo de perdidas: {risk * 100}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "781dc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 1:\n",
      "Intervalo de confianza del 95%: (-1020900.9483793724 , 9479763.533583675)\n",
      "Beneficio promedio: 4259385.269105923\n",
      "Cuantil del 97.5 %: 9479763.533583675\n",
      "Cuantil del 2.5 %: -1020900.9483793724\n",
      "Riesgo de perdidas: 6.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Region 1:\")\n",
    "bootstrapping(sample_target_1, sample_predictions_1, wells, investment, product_income_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e15983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 2:\n",
      "Intervalo de confianza del 95%: (688732.2537050088 , 9315475.912570495)\n",
      "Beneficio promedio: 5152227.734432898\n",
      "Cuantil del 97.5 %: 9315475.912570495\n",
      "Cuantil del 2.5 %: 688732.2537050088\n",
      "Riesgo de perdidas: 1.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Region 2:\")\n",
    "bootstrapping(sample_target_2, sample_predictions_2, wells, investment, product_income_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad7a4654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 3:\n",
      "Intervalo de confianza del 95%: (-1288805.473297878 , 9697069.541802654)\n",
      "Beneficio promedio: 4350083.627827557\n",
      "Cuantil del 97.5 %: 9697069.541802654\n",
      "Cuantil del 2.5 %: -1288805.473297878\n",
      "Riesgo de perdidas: 6.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"Region 3:\")\n",
    "bootstrapping(sample_target_3, sample_predictions_3, wells, investment, product_income_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ef490",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Como podemos observar tras aplicar la tecnica de bootstrapping, obtenemos el beneficio promedio, los intervalos de confianza y los riesgos de perdidas de cada una de las regiones, en donde destaca la region 2 que tiene el mas alto beneficio promedio de los 3 con 5,152,227.7344, el menor riesgo de los 3 con 1% y a diferencia de las demas regiones el limite inferior del intervalo de confianza es positivo siendo que los limites inferiores de los demas es negativo. Dejando asi la region 2 como la region mas optima para proponer a ser elegida.\n",
    "\n",
    "Cabe destacar aunque inicialmente la region 1 parecía más atractiva en cuestion a que era ganancia potencial mas alta, la evaluación detallada de los resultados del bootstrapping confirman que la region 2 es la mejor opción, teniendo de beneficio superior y un bajo riesgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22ca59",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1dc12f",
   "metadata": {},
   "source": [
    "## Conclusión general <a id='end'></a>\n",
    "\n",
    "Tras haber realizado y completado cada uno de los pasos de este proyecto desde el analisis exploratorio, la separacion de los conjuento de datos de entrenamiento y validacion de los cuales fue 75% y 25%, el entrenamiento y predicciones de un modelo de regresion lineal, los calculos para obtener la ganancia potencial de las regiones y finalmente aplicar la tecnica de bootstrapping que fue de gran ayuda para una mayor evaluacion a las regiones, obteniendo asi el beneficio promedio, los intervalos de confianza del 95% y los riesgos de perdidas de cada region. Con todo esto para poder elegir la region mas optima para abrir nuevos pozos petroleros (siendo la region 2), mencionando la creacion de funciones lo cual fue de ayuda para la reutilizacion de codigo al momento de aplicarlo para cada una de las regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb48cd9",
   "metadata": {},
   "source": [
    "[Volver a Contenidos](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
